# Yahoo LLM Eval

Este proyecto implementa un entorno de simulaciÃ³n para evaluar el desempeÃ±o de un sistema de **LLM + cachÃ©** usando datos de Yahoo! Answers.  
La arquitectura estÃ¡ basada en **Docker Compose** y servicios modulares.

---

## ğŸ“‚ Estructura del proyecto

```
yahoo-llm-eval/
â”‚â”€â”€ data/
â”‚    â””â”€â”€ train.csv          # Dataset base con preguntas/respuestas
â”‚
â”‚â”€â”€ service/
â”‚    â”œâ”€â”€ setup/             # Scripts iniciales y configuraciÃ³n
â”‚	â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ *load_data.py
â”‚    â”œâ”€â”€ llm_proxy/         # Servicio que conecta con el LLM (Gemini)
â”‚	â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ *llm_proxy.py
â”‚    â”œâ”€â”€ traffic_generator/ # Generador de trÃ¡fico (simulaciÃ³n de requests)
â”‚	â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ *traffic_generator.py
â”‚    â””â”€â”€ score/             # Servicio de evaluaciÃ³n de respuestas
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ *score.py
â”‚
â”‚â”€â”€ docker-compose.yml      # OrquestaciÃ³n de servicios
â”‚â”€â”€ requirements.txt        # Dependencias de Python
â”‚â”€â”€ .env                    # Variables de entorno (llave de Gemini)
```

---

## âš™ï¸ Requisitos previos

- **Python 3.10+** y `venv` habilitado
- **Docker** y **Docker Compose**
- Llave de acceso a **Gemini API** (configurada en `.env`)

---

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

### 1. Clonar repositorio y entrar en la carpeta raÃ­z
```bash
cd yahoo-llm-eval
```

### 2. Activar entorno virtual de Python
```bash
python -m venv venv
source venv/bin/activate    # Linux/Mac
venv\Scripts\activate     # Windows
```

Instalar dependencias si deseas ejecutar mÃ³dulos locales:
```bash
pip install -r requirements.txt
```

### 3. Construir y levantar los servicios
```bash
docker compose up -d --build
```

### 4. Cargar los datos al sistema
```bash
docker compose run --rm load_data
```

### 5. Generar trÃ¡fico simulado
```bash
docker compose run --rm traffic
```

---

## ğŸ“Š Flujo de trabajo

1. **Carga de datos** â†’ `load_data` importa el `train.csv` a la base del sistema.  
2. **Proxy LLM** â†’ `llm_proxy` maneja la conexiÃ³n al modelo (Gemini).  
3. **Generador de trÃ¡fico** â†’ `traffic_generator` simula peticiones de usuarios.  
4. **Score** â†’ `score` mide la similitud de respuestas (TF-IDF y mÃ©tricas).  

---

## ğŸ”‘ Variables de entorno

El archivo `.env` debe contener:
```env
GEMINI_API_KEY=key correspondiente a usuario
```

---

## ğŸ›‘ Detener servicios
```bash
docker compose down
```

---

## âœ¨ Notas
- El sistema estÃ¡ pensado para entornos con recursos limitados, por lo que es recomendable ejecutar trÃ¡fico en lotes pequeÃ±os.  
- Puedes modificar los parÃ¡metros de trÃ¡fico en `traffic_generator` para ajustar la intensidad de consultas.  
